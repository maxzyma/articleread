# 刷新 Google AlphaEvolve 进化结果，百度开源 Agent 开发框架 LoongFlow

> 来源：微信公众号 百度Geek说，2026-01-26
> 原文链接：https://mp.weixin.qq.com/s/P46itmfjs9Xs5fdHoxJKlw

LoongFlow 是**百度百舸团队发布**的一个开源的、旨在让 AI 学会「专家级思考」的智能体开发框架。

基于 LoongFlow 框架，团队开发了「通用算法发现」和「机器学习」两个开箱即用的 Agent，它们已在多项顶尖挑战中证明实力：

- **数学领域**：在 **11 个问题上超越人类数学家已知最佳结果**，在 **7 个问题上刷新了 Google AlphaEvolve 的进化结果**，刷新 SOTA
- **MLE-bench 评测**：在模拟 Kaggle 数据科学竞赛中**独立斩获 23 块金牌**
- **进化效率**：与 OpenEvolve、ShinkaEvolve 等进化智能体对比，**进化效率提升超 60%，迭代成功率 100%**

---

## 智商与方法的距离：当聪明遇到了复杂

爱迪生发明灯泡的故事常被用以诠释坚持——他进行了超过 6000 多次的实验，最终找到了可用的碳化竹丝。

但换一个角度思考：如果他只是盲目、随机地尝试每一种材料，面临的可能是上万次失败，甚至终其一生也无法完成发明。

幸运的是，爱迪生并非完全随机尝试。他会观察每次失败，碳化竹丝为何比铂丝更耐用？这种从失败中提炼规律、指导下一步实验的能力，才是他成功的真正关键。

### 长程复杂推理任务的特征

爱迪生面对的，是一个典型的「长程复杂推理任务」：

- **可能性空间巨大**：成千上万种材料、不同的处理工艺、多种形状尺寸
- **需要多轮迭代**：不能一次性得出答案，必须「尝试 - 观察 - 调整」循环
- **结果反馈延迟**：只有完整实施后，才能知道效果如何
- **需要积累智慧**：每一次失败都应让下一次尝试更聪明

这些任务的共同点是：光有知识和计算能力不够，还需要一套能引导探索、积累经验、避免重复错误的思考框架。

---

## Agent 演进：从「单步执行」到「持续进化」

为了让 AI 从「博学的参谋」成长为能自主解决复杂问题的「专家」，智能体（Agent）技术沿着解决日益复杂问题的方向演进。

### 阶段一：单任务推理智能体（ReAct 范式）

这类智能体让 AI 学会了在单个任务中进行「推理 - 行动 - 观察」的逐步思考。

例如，要回答「今天北京天气如何并推荐一家餐厅」，它会先推理「我需要调用天气 API」，执行查询后，再根据结果推理「现在需要搜索餐厅排行榜」。

其本质是**针对单任务的序列决策**，像一个可靠的「单任务执行者」。

### 阶段二：长程任务进化智能体（AlphaEvolve、OpenEvolve）

当目标变为「发现一个超越现有水平的新算法」或「优化一个机器学习 pipeline」时，需要在多轮迭代中保持方向、积累智慧。

进化智能体框架引入了新思路：它们维护一个「解决方案种群」，通过评估、选择、优化调整（由 LLM 驱动）来一代代进化，追求持续改进。

然而，早期进化智能体常把 LLM 当作一个随机调整器，导致进化过程类似蒙眼随机漫步，效率低下。它们虽然引入了「进化」概念，但在「如何智能地进化」这一关键方法上，仍有巨大提升空间。

---

## LoongFlow：开源的「专家级思考」框架

**LoongFlow（龙流）**正是为满足这一需求而生的开发框架。

LoongFlow 的命名，致敬了王阳明「龙场悟道」所揭示的「知行合一」真谛——真知必在于行，而行必有真知指导。这正契合框架的抱负：打破 AI 认知与行动间的隔阂，让专业的经验与方法，能在持续的智能实践中转化为可进化、可复用的生产力。

![LoongFlow 框架概述](https://cdn.jsdelivr.net/gh/maxzyma/articleread/loongflow-baidu-agent-framework/images/image_01.png)

### 核心创新

LoongFlow 的核心创新在于两套相互咬合的设计：

1. **PES（Plan-Execute-Summarize）范式**：为进化注入「科学家思维」
2. **混合进化记忆系统（Hybrid Evolutionary Memory）**：构建专属的「战略智库」

二者结合，LoongFlow 实现了从「随机演化」到「定向认知进化」的范式升维。

---

## PES 范式：为进化注入「科学家思维」

LoongFlow 没有将进化交给随机性，而是为每一次迭代设计了结构化的认知阶段：**规划、执行、总结**。

![PES 范式](https://cdn.jsdelivr.net/gh/maxzyma/articleread/loongflow-baidu-agent-framework/images/image_02.png)

### Plan 规划

在生成新一代方案前，智能体会扮演「战略分析师」的角色：

- 深度分析当前采样方案
- 检索「战略智库」（混合进化记忆系统）中所有的历史经验与失败教训
- 制定出一份目标清晰、规避已知陷阱的「进化蓝图」

这从根本上杜绝了盲目尝试。

### Execute 执行

「执行」阶段如同一个配备了全系专业工具包的智能施工队，其关键在于「因题施策」的动态适配能力：

- 面对数学证明 → 严谨的「逻辑验证器」
- 编写代码时 → 即写即测的「交互解释器」
- 进行数据分析时 → 高效的「智能查询生成器」

这种灵活性，结合「快速本地验证」机制，确保了高质量输出，从源头节省了计算资源。

### Summarize 总结

行动之后，「总结」模块承担起「复盘官」的职责：

- 不满足于简单的得分
- 深入剖析「规划蓝图」与「执行结果」之间的差距
- 提炼出「为何成功或失败」的因果洞察

这些结构化的经验被转化为下一代规划时可检索的宝贵知识。

---

## 混合进化记忆系统：体系化的经验治理

如果说 PES 是单次探索的「优质生产线」，那么**混合进化记忆系统（Hybrid Evolutionary Memory）**就是确保整个探索事业可持续发展的「智慧管理体系」。

![混合进化记忆系统](https://cdn.jsdelivr.net/gh/maxzyma/articleread/loongflow-baidu-agent-framework/images/image_03.png)

### 多岛模型

在内部建立多个独立的「探索特区」，允许不同的技术路线并行发展，相互隔离又定期交流，有效维持了探索的多样性，避免思维过早趋同。

### MAP-Elites

如同一个多维的「杰出方案陈列馆」。系统不仅按成绩，更按行为特征（如算法复杂度、计算效率）对解决方案进行归档。这意味着，一个在某项特性上表现极佳但总分并非最高的方案，同样会被珍藏，为未来的跨界创新保留火种。

### 自适应玻尔兹曼选择

智能的「资源调度官」，根据种群探索的实时状态（如多样性熵值），动态调节关键参数，智能切换策略：是在全局鼓励冒险开拓新边疆，还是在局部集中力量深耕最优领地。

---

## 实战验证：顶尖竞技场上的性能标杆

任何方法的价值，最终由实践检验。基于 LoongFlow 框架，百度百舸团队开发了「通用算法发现」和「机器学习」两个开箱即用的 Agent。

### 数学成就：全面刷新人类与 AI 的纪录

在陶哲轩和 AlphaEvolve 发布的数学挑战中，LoongFlow 取得了令人瞩目的成绩：

- 在 **11 个问题上超越了人类数学家已知最佳结果**
- 在 **7 个问题上超越谷歌 AlphaEvolve 的进化结果**，刷新 SOTA

例如，在「圆填充」问题中，如何在给定形状内排列多个圆，使它们互不重叠且尽可能填满空间？LoongFlow 找到了比数学家多年探索和 AlphaEvolve 的进化结果更优的排列方式。

![数学成就对比](https://cdn.jsdelivr.net/gh/maxzyma/articleread/loongflow-baidu-agent-framework/images/image_04.png)

### 工程成就：在 23 项真实挑战中夺得金牌

在 OpenAI 发布的模拟 Kaggle 数据科学竞赛的 **MLE-bench 评测**中，由 LoongFlow 驱动的机器学习智能体，已独立斩获了 **23 枚金牌**。

任务涵盖从「病理切片癌症检测」到「预测火山喷发」等高度专业且数据复杂的现实场景。这证明 LoongFlow 不仅能解决抽象数学问题，更具备构建、优化端到端工业级解决方案的工程能力。

![MLE-bench 金牌](https://cdn.jsdelivr.net/gh/maxzyma/articleread/loongflow-baidu-agent-framework/images/image_05.png)

### 效率成就：以 60% 的效率优势稳定胜出

在相同任务下，与 OpenEvolve、ShinkaEvolve 等进化智能体框架对比：

- **进化效率提升超 60%**：用最少的生成评估次数，发现最好的结果
- **迭代成功率 100%**：在多次重复实验中稳定达成目标，而基线方法常因陷入局部最优或进化太慢而失败

![效率对比](https://cdn.jsdelivr.net/gh/maxzyma/articleread/loongflow-baidu-agent-framework/images/image_06.png)

---

## 系统的协同魔力：1 + 1 > 2

PES 范式与混合进化记忆系统并非独立运作，它们的深度耦合是效能的倍增器。

![系统协同](https://cdn.jsdelivr.net/gh/maxzyma/articleread/loongflow-baidu-agent-framework/images/image_07.png)

- **规划时**：分析师（Planner）从「战略智库」（混合进化记忆系统）中获取精选、多样化的历史方案作为蓝图依据
- **执行时**：施工队（Executor）利用其动态适配的工具进行快速自我质检
- **总结时**：复盘官（Summarizer）产出的因果洞察被系统化地反馈回「战略智库」

正是这种微观认知与宏观管理在每一个迭代周期内的紧密配合，使得 LoongFlow 的整个探索过程呈现出强大的方向性、累积性和加速性。

---

## 从千次试错到百次探索：AI 解题的范式转变

基于 LoongFlow 在实际复杂任务中的表现，我们看到了一个根本性的转变。

在类似规模的探索空间中，传统随机搜索可能需要成千上万次尝试，而 LoongFlow 的定向认知进化方法，能够**减少约 60% 以上的无效探索**，并将**迭代成功率提升至接近 100%**。

这意味着，如果爱迪生当时拥有这样的系统，寻找合适灯丝的过程可能从「上千次盲目试错」压缩为「数百次智能探索」——每一次尝试都建立在前一次的经验总结之上，每一次失败都直接指引着下一次的方向。

但这不仅仅是数字上的缩减。LoongFlow 带来的真正价值在于**范式的变革**：

> 它将人类「假设 - 检验 - 学习」的科学精神，以软件架构的形式固化、增强并规模化。它让智能体不再是单纯消耗算力进行蛮力搜索，而是能够像最严谨的科学家那样，有策略地规划、有工具地执行、有深度地反思。

从「随机试错」到「定向思考」，这标志着 AI 解决问题方式的**质变**——答案不再依赖于尝试的次数，而是源于思考的深度与系统性。

---

## 链接

**GitHub：**
https://github.com/baidu-baige/LoongFlow

**技术报告：**
https://arxiv.org/abs/2512.24077
