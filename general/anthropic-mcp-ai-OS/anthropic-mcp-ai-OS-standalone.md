# OpenAI 的最强对手，离「AI Windows」又近了一步

> 来源：微信公众号 极客公园，2026-01-27
> 原文链接：https://mp.weixin.qq.com/s/JDqeh3N7JlrqJpkqRRzRTA

**Anthropic 又一次证明，「超级底层」，才是 AI 成功的关键。**

近日，AI 模型公司 Anthropic 为其旗舰产品 **Claude** 带来了一项看似不起眼、实则影响深远的更新。

在 Claude 桌面应用的「连接器」部分，新增了一个名为「**精选**」的分类，其中整合了与 **Figma、Gemma、Canva、GitHub** 等生产力工具的深度集成。

这并非一次简单的功能罗列。这一功能背后的核心，是 **Model Context Protocol (MCP)** 服务的大规模上线。

---

## 从「聊天」到「调度」，MCP 重塑 AI 工作流

### 当前痛点

过去一年，AI 应用如雨后春笋，有擅长写作的 ChatGPT，能画图的 Midjourney，可编程的 Cursor，以及分析数据的各种 AI 工具。

对用户而言，这带来一个典型困境——人们需要在不同应用间不断复制粘贴、切换上下文。

比如，想让 AI 根据一份数据报告生成图表并写入文章，就需要在数据分析工具、图表生成器和写作工具之间手动搬运数据。

**效率在切换中流失，灵感在搬运中中断。**

### MCP 协议的核心思想

Anthropic 在去年给出的解决方案就是 **MCP**。

**MCP 协议的核心思想**，是为 AI 模型访问外部资源定义一个统一的「插座」标准。

开发者可以为任何工具（从本地命令行到云服务）编写一个符合 MCP 标准的「服务器」。Claude（作为「客户端」）通过这个标准接口与之通信，无需了解每个工具的内部实现细节。

这就像为所有电器制定了统一的插头标准（MCP），而 Claude 则是一个配备了万能插座的智能中枢。

### Anthropic vs OpenAI：两条不同的路径

与 OpenAI 的 GPTs 或 Assistants API 相比，Claude 这次上线的 MCP 服务体现了其鲜明的产品哲学：

1. **安全与权限控制是基石**：所有连接都需要用户明确授权，且运行在用户指定的环境中（本地或可信远程服务器）
2. **深度集成而非浅层连接**：与 Figma、GitHub 等的合作并非简单的 API 调用包装
3. **从「精选」切入，控制体验**：Anthropic 没有开放一个鱼龙混杂的「市场」，而是以「精选」形式推出首批深度合作的工具

对比来看：
- **OpenAI 的路径**：更「开放」和「平台化」，鼓励大量开发者创建功能各异的 GPTs，但导致碎片化和质量参差
- **Anthropic 的路径**：更「克制」和「集成化」，亲自下场与头部生产力工具深度耦合，优先保障核心工作流的高质量打通

---

## 在 AI 对话框里完成工作

### 旧模式

你在 Figma 中完成了一个网站首页设计。

你想评估其设计系统的一致性，于是截图，打开 ChatGPT 或 Claude 网页版，上传图片，询问：「请分析这个设计稿的配色和间距是否符合 Material Design 规范？」

你得到一些文本建议。如果想调整，你需要回到 Figma，手动找到对应图层进行修改。

接着，你需要为这个设计写一份说明文档。你再次复制设计理念，粘贴到 Notion 或 Google Docs，让 AI 协助扩充。

最后，你需要基于设计稿生成前端代码框架。你又得把设计稿相关信息描述给 Cursor 或 GitHub Copilot。

### 新模式（Claude with MCP）

你在桌面打开 Claude 应用，点击连接器，授权连接到你本地的 Figma 和 GitHub。

你对 Claude 说：「分析我当前打开的『官网首页』Figma 文件，检查设计系统一致性，并生成一份简要的设计说明文档。」

Claude 通过 MCP **直接读取 Figma 文件的结构化数据**（不仅是图片，包括图层、样式、变量），给出精准分析，并生成文档。

你接着说：「很好，基于这个设计，为我的 Next.js 项目生成一个对应的 React 组件骨架，并提交到 GitHub 仓库的 feat/homepage 分支。」

Claude 调用 MCP 工具，生成代码文件，并通过 GitHub 接口完成提交。

### 对比：从问答到委派（Delegation）

从对比可以看出，新模式下体验的飞跃在于，**用户始终在一个对话界面中，用自然语言指挥**。

Claude 扮演了「调度员」和「执行者」的角色，背后复杂的工具切换和数据搬运被 MCP 协议无声地消化了。

**这不再是问答，而是 delegation（委派）。**

对于设计师、产品经理和全栈开发者来说，这意味着**心智状态不再被工具壁垒频繁打断**。

---

## AI 时代「操作系统」雏形？

抛开具体的工具集成，MCP 协议的推出，揭示了 Anthropic 一个更深层的战略意图：

**争夺 AI 时代「操作系统」的定义权。**

在个人电脑时代，操作系统（如 Windows、macOS）通过统一的 API 管理所有硬件和软件资源。

在移动互联网时代，iOS 和 Android 通过应用商店和系统接口，成为生态的核心。

**而在 AI 原生时代，谁定义了 AI 模型与万千数字工具交互的标准协议，谁就掌握了生态的枢纽位置。**

### 对开发者的影响

MCP 协议本身是开源的。这意味着任何模型或应用都可以实现它。如果它被广泛采纳，将形成一种「去中心化」的 AI 工具生态。

**MCP 降低了开发 AI 智能体（Agent）的门槛**。开发者无需针对每个模型（Claude, GPT, Gemini）都适配一遍插件系统，只需编写一个标准的 MCP 服务器，理论上就能被所有支持 MCP 的模型调用。

### 对算力成本的潜在影响

将专业工具的能力（如设计检查、代码执行）通过 MCP 外包，可以让大语言模型更专注于自己擅长的规划、理解和推理，而不是试图在参数中硬编码所有专业知识。

这可能导致未来出现更「轻量」、更「通用」的核心模型，依赖外部工具网络完成复杂任务，从而**降低对极致模型规模的依赖**。

---

## 挑战与展望

当然，挑战依然巨大。工具间的兼容性、复杂工作流的错误处理、长期记忆和状态保持，都是尚未完全解决的难题。

**MCP 协议目前更像是一个优秀的「设备驱动」标准**，但距离一个完整的「操作系统」还有很长的路要走。

Claude 上线 MCP 服务，不是一次简单的功能更新。它是 Anthropic 在 AI 竞争进入深水区后，打出的一张极具分量的战略牌。

它避开了与 OpenAI 在纯模型能力上的「军备竞赛」，转而开辟了「**模型即枢纽**」的新战场。

其真正的价值不在于今天能连接 Figma 还是 GitHub，而在于它正在悄然铺设一条轨道，这条轨道可能最终决定，未来的 AI 生产力是以「**单个超级应用**」为中心，还是以一个「**可自由插拔的智能体网络**」为中心。

对于用户和开发者来说，一个更开放、更集成的 AI 工具生态，或许比一个参数多几万亿的模型，更能带来实质性的效率革命。

**这场关于 AI「操作系统」的竞赛，刚刚拉开序幕。**
