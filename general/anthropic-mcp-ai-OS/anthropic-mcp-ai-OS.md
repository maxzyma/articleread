# OpenAI 的最强对手，离「AI Windows」又近了一步

> 来源：微信公众号 极客公园，2026-01-27
> 原文链接：https://mp.weixin.qq.com/s/JDqeh3N7JlrqJpkqRRzRTA

**Anthropic 又一次证明，「超级底层」，才是 AI 成功的关键。**

作者｜桦林舞王

编辑｜靖宇

当全球都在为一条红色的龙虾——**「Clawdbot」**而兴奋异常时，Anthropic 悄悄上线了一个新功能。

近日，AI 模型公司 Anthropic 为其旗舰产品 Claude 带来了一项看似不起眼、实则影响深远的更新。在 Claude 桌面应用的「连接器」部分，新增了一个名为「精选」的分类，其中整合了与 **Figma、Gemma、Canva、GitHub** 等生产力工具的深度集成。

这并非一次简单的功能罗列。这一功能背后的核心，是 **Model Context Protocol (MCP)** 服务的大规模上线。

简单来说，MCP 是一个让 AI 模型安全、标准化地「连接」到外部工具和数据的协议。用户现在可以通过远程连接，授权 Claude 直接访问这些第三方服务的数据，并在对话中调用其功能。例如，你可以让 Claude 分析 Figma 设计稿并提出修改建议，或者根据 GitHub 仓库的代码生成文档。

这并非只是 Anthropic 和第三方合作伙伴的简单合作，**它标志着 Claude 从一个被动的「聊天机器人」，向一个主动的、能调度外部资源的「智能体平台」迈出了关键一步。**

---

## 01. 从「聊天」到「调度」，MCP 重塑 AI 工作流

要理解 MCP 的价值，首先要看清当前 AI 应用的痛点。

过去一年，AI 应用如雨后春笋，有擅长写作的 ChatGPT，能画图的 Midjourney，可编程的 Cursor，以及分析数据的各种 AI 工具。对用户而言，这带来一个典型困境——人们需要在不同应用间不断复制粘贴、切换上下文。

比如，想让 AI 根据一份数据报告生成图表并写入文章，就需要在数据分析工具、图表生成器和写作工具之间手动搬运数据。

**效率在切换中流失，灵感在搬运中中断。**

Anthropic 在去年给出的解决方案就是 MCP，MCP 协议的核心思想，是为 AI 模型访问外部资源定义一个统一的「插座」标准。

开发者可以为任何工具（从本地命令行到云服务）编写一个符合 MCP 标准的「服务器」。Claude（作为「客户端」）通过这个标准接口与之通信，无需了解每个工具的内部实现细节。

这就像为所有电器制定了统一的插头标准（MCP），而 Claude 则是一个配备了万能插座的智能中枢。

与 OpenAI 的 GPTs 或 Assistants API 相比，Claude 这次上线的 MCP 服务体现了其鲜明的产品哲学：

### 安全与权限控制是基石
所有连接都需要用户明确授权，且运行在用户指定的环境中（本地或可信远程服务器）。数据不会无故流向 Anthropic 的服务器。这延续了 Claude 一贯的「Constitutional AI」（宪法 AI）安全理念。

### 深度集成而非浅层连接
与 Figma、GitHub 等的合作并非简单的 API 调用包装。从演示看，Claude 能理解 Figma 组件的设计语义，能基于 GitHub 的代码变更历史给出建议。这需要深入的工具语义理解，而不仅仅是发送一个 HTTP 请求。

### 从「精选」切入，控制体验
Anthropic 没有开放一个鱼龙混杂的「市场」，而是以「精选」形式推出首批深度合作的工具。这保证了初期用户体验的完整性和可靠性，避免了早期 GPT Store 的质量混乱问题。

对比来看，OpenAI 的路径更「开放」和「平台化」，鼓励大量开发者创建功能各异的 GPTs，但导致碎片化和质量参差。

**Anthropic 则选择了更「克制」和「集成化」的路径，亲自下场与头部生产力工具深度耦合，优先保障核心工作流的高质量打通。**

后者对于安全和可控的执着，以及在 B 端的优良声誉，都决定了 Anthropic 和 OpenAI 完全不同的策略。

---

## 02. 在 AI 对话框里完成工作

Anthropic 的连接器，究竟如何，可以模拟一个真实的使用场景，来感受这种范式转变。

**旧模式下：**

你在 Figma 中完成了一个网站首页设计。你想评估其设计系统的一致性，于是截图，打开 ChatGPT 或 Claude 网页版，上传图片，询问：「请分析这个设计稿的配色和间距是否符合 Material Design 规范？」

你得到一些文本建议。如果想调整，你需要回到 Figma，手动找到对应图层进行修改。

接着，你需要为这个设计写一份说明文档。你再次复制设计理念，粘贴到 Notion 或 Google Docs，让 AI 协助扩充。

最后，你需要基于设计稿生成前端代码框架。你又得把设计稿相关信息描述给 Cursor 或 GitHub Copilot。

**新模式（Claude with MCP）：**

你在桌面打开 Claude 应用，点击连接器，授权连接到你本地的 Figma 和 GitHub。

你对 Claude 说：「分析我当前打开的『官网首页』Figma 文件，检查设计系统一致性，并生成一份简要的设计说明文档。」

Claude 通过 MCP 直接读取 Figma 文件的**结构化数据**（不仅是图片，包括图层、样式、变量），给出精准分析（「主标题的字体层次对比度不足，建议将 H1 加粗一个等级」），并生成文档。

你接着说：「很好，基于这个设计，为我的 Next.js 项目生成一个对应的 React 组件骨架，并提交到 GitHub 仓库的 feat/homepage 分支。」

Claude 调用 MCP 工具，生成代码文件，并通过 GitHub 接口完成提交。

从对比可以看出，**新模式下体验的飞跃在于，用户始终在一个对话界面中，用自然语言指挥。**

Claude 扮演了「调度员」和「执行者」的角色，背后复杂的工具切换和数据搬运被 MCP 协议无声地消化了。

**这不再是问答，而是 delegation（委派）。**

对于设计师、产品经理和全栈开发者来说，这意味着心流状态不再被工具壁垒频繁打断。

---

## 03. AI 时代「操作系统」雏形？

抛开具体的工具集成，MCP 协议的推出，揭示了 Anthropic 一个更深层的战略意图：

**争夺 AI 时代「操作系统」的定义权。**

在个人电脑时代，操作系统（如 Windows、macOS）通过统一的 API 管理所有硬件和软件资源。在移动互联网时代，iOS 和 Android 通过应用商店和系统接口，成为生态的核心。而在 AI 原生时代，**谁定义了 AI 模型与万千数字工具交互的标准协议，谁就掌握了生态的枢纽位置。**

### 对开发者来说
MCP 降低了开发 AI 智能体（Agent）的门槛。开发者无需针对每个模型（Claude, GPT, Gemini）都适配一遍插件系统，只需编写一个标准的 MCP 服务器，理论上就能被所有支持 MCP 的模型调用。这带来了互操作性的希望。

### 开源的影响
MCP 协议本身是开源的。这意味着任何模型或应用都可以实现它。如果它被广泛采纳，将形成一种「去中心化」的 AI 工具生态，而非被某个巨头完全掌控的围墙花园。但目前，Anthropic 通过 Claude 的率先深度集成和「精选」生态，占据了事实上的引领者位置。

### 对算力成本的潜在影响
将专业工具的能力（如设计检查、代码执行）通过 MCP 外包，可以让大语言模型更专注于自己擅长的规划、理解和推理，而不是试图在参数中硬编码所有专业知识。这可能导致未来出现更「轻量」、更「通用」的核心模型，依赖外部工具网络完成复杂任务，从而降低对极致模型规模的依赖。

当然，挑战依然巨大。工具间的兼容性、复杂工作流的错误处理、长期记忆和状态保持，都是尚未完全解决的难题。

**MCP 协议目前更像是一个优秀的「设备驱动」标准，但距离一个完整的「操作系统」还有很长的路要走。**

Claude 上线 MCP 服务，不是一次简单的功能更新。它是 Anthropic 在 AI 竞争进入深水区后，打出的一张极具分量的战略牌。它避开了与 OpenAI 在纯模型能力上的「军备竞赛」，**转而开辟了「模型即枢纽」的新战场。**

其真正的价值不在于今天能连接 Figma 还是 GitHub，而在于它正在悄然铺设一条轨道，这条轨道可能最终决定，未来的 AI 生产力是以「单个超级应用」为中心，还是以一个「可自由插拔的智能体网络」为中心。

对于用户和开发者来说，一个更开放、更集成的 AI 工具生态，或许比一个参数多几万亿的模型，更能带来实质性的效率革命。

**这场关于 AI「操作系统」的竞赛，刚刚拉开序幕。**
