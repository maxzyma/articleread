# 大模型圈娱乐化逼疯人！OpenAI 七年元老离职首发声：谷歌赢麻？不过是 OpenAI 失误了！

> 来源：InfoQ 公众号，编译 | Tina，2026-01-23
> 原文链接：https://mp.weixin.qq.com/s/81OnMVR5svDURu_2mHUypQ

![封面图](https://cdn.jsdelivr.net/gh/maxzyma/articleread/openai-veteran-jerry-tworek-interview/images/image_01.png)

---

这不是离职八卦，而是在一个把技术做成剧情、把研究变成围观的行业里，扛了七年高压后的选择。

2026 年的第一个月，**Jerry Tworek** 离开 OpenAI 的消息传出来时，几位 OpenAI 的员工在 X 上几乎失控地发声："我真的崩溃了""这太难受了"。大家的反应像是：这事来得太突然，也太重。

Jerry 是现代 AI 浪潮背后最有影响力、却也最少公开露面的关键人物之一。2019 年加入 OpenAI 时，当时该公司还只有约 30 名员工。他参与了许多最重要的项目，包括后来被称为 Q-Star 和 Strawberry 的推理方法，最终发展成为 o1 推理模型。

这次离职后，他在接受 **Core Memory** 的播客采访时解释了原因：他想从事有风险的基础研究，这种研究在像 OpenAI 这样的公司已经不可能进行了，因为像用户增长这样的指标才是优先考虑的。他对 ChatGPT 广告的看法体现了研究与商业化之间的脱节："**这是一种商业策略，而我负责训练模型。**" 这番言论印证了有关 OpenAI 人工智能研究与产品开发之间日益加剧的分歧的传言。

Tworek 指出，创新不足的原因有很多。最佳模型的竞争异常激烈，公司需要不断展现实力才能留住用户并证明 GPU 成本的合理性。僵化的组织结构更是雪上加霜，组织架构图决定了哪些研究是可能的：团队各自为政，职责分明，跨团队研究难以开展。

这场采访，也是一次"离职解读"，Jerry 还批评了整个人工智能行业，指出所有主要的人工智能公司都在开发几乎相同的技术，产品也几乎没有区别，这迫使研究人员追求短期利益，而不是实验性突破。

在 Tworek 看来，**谷歌之所以能够在 AI 竞赛中成功追赶 OpenAI，本质上是 OpenAI 自身的失误**。他表示，这家 AI 实验室犯了一些错误，行动过于缓慢，没能充分利用自己原本拥有的巨大领先优势；而与此同时，谷歌则做出了许多正确的决策。

与这种"慢得不该那么慢"的状态形成对照的，是 Tworek 对 **Anthropic** 的评价。在播客中，他高度评价了这家 OpenAI 最强的初创公司对手，认为它在过去一年里展现出了一种罕见的"清晰感"：算力更少、团队更小，却异常专注，执行力极强。

随着谈话继续，话题很快从技术转向了另一件更微妙的事。

Jerry 说，这几年最让他感到"不对劲"的，并不只是研究路线，而是整个大模型行业正在发生的变化。他形容现在的状态有点像这样：你做出一个新东西，大家还没真正弄清楚它是什么，它已经被卷进了一整套剧情里。谁离职、谁跳槽、谁被挖、谁"内部有分歧"，每天都像连续剧更新；湾区像一个巨大的转会市场。

---

## 1 当整个大模型行业只剩下一套"配方"，有些人宁愿离场

**主持人**：今天我们请来重量级嘉宾——OpenAI 的 Jerry Tworek。他在 AI 圈算是"活传奇"那种人，而且刚刚离开 OpenAI，所以这期信息非常新、也非常重磅。我刷到不少 OpenAI 的同事在 X 上直接说"我崩溃了""太难受了"。这就能看出来他在内部的分量。

他主导或参与了 OpenAI 很多最重要的项目。这一波"推理模型"的时代，在很大程度上也和 Jerry 有关。

Jerry，你好。你身上有一种……"刚失业的光芒"。

**Jerry**：我已经失业八天了，确实是一种变化。我已经很久没有失业过了，但这件事也有很多好处。比如我现在晒太阳的时间多了很多。

**主持人**：那这期节目就算你的"离职访谈"了。你大概是 2019 年加入 OpenAI 的。你来自波兰，在来 AI 领域之前，和很多 AI 从业者一样，曾经在高频交易相关的领域工作过。在 OpenAI，你参与或领导了很多大家非常熟悉的重要项目。最近，很多人听说过 Strawberry、o1，以及这波"推理模型"的兴起。

![Jerry Tworek 离职声明](https://cdn.jsdelivr.net/gh/maxzyma/articleread/openai-veteran-jerry-tworek-interview/images/image_04.png)

然后，如大家所知，你最近刚离开 OpenAI。你在推文中写道：

> **大家好，我做了一个艰难的决定：离开 OpenAI。**
>
> **我在这里将近七年，经历了很多美好与疯狂的时刻——但美好远远多于疯狂。**
>
> **我非常享受和这支团队共事的时光。我有机会在"机器人上的强化学习规模化"还没流行之前就参与其中；训练了世界上最早的一批代码模型，推动了 LLM 编程革命；在"Chinchilla（缩放规律）"还没被叫作 Chinchilla 之前就发现了它；参与了 GPT-4 和 ChatGPT 的工作；最近则是组建了一支团队，建立了一种训练与推理算力规模化的新范式——我们通常把它称为"推理模型"。**
>
> **我在这里结识了许多朋友，有些夜晚也在办公室度过；我参与并见证了相当多的技术突破；也和许多我视为至亲的人一起欢笑、一起担忧。我有幸招募并壮大了——在我看来——世界上最强的机器学习团队。**
>
> **这段旅程非常精彩。虽然我将离开，去探索一些在 OpenAI 很难开展的研究方向，但这依然是一家特别的公司、一个特别的地方，它已经在全人类的历史中占据了永恒的一席之地。**

**主持人**：但说真的，你那条离职帖写得很好，而且挺真情实感的。你在那里待了七年，经历了巨大的变化。从你的视角看，这七年是什么感觉？

**Jerry**：老实说，我在 OpenAI 的每一年，都像是在一家完全不同的公司里。无论是公司本身的高速增长，还是整个 AI 世界的变化速度，都非常罕见。我不觉得历史上有很多类似的例子。我很高兴自己亲身经历了这一切。几乎每一个阶段，情况都完全不同。

**主持人**：你 2019 年加入的时候，公司大概只有 30 人左右？

**Jerry**：对，大概就是那个规模。

**主持人**：那现在呢？几千人？

**Jerry**：已经没法数清楚了。现在是一家规模非常大的公司，有很多办公室，全球各地都有团队。现在几乎很难找到没听说过 OpenAI 的人。我加入的时候，还是几个小团队各自在做自己的小研究项目。那时唯一始终不变的，是野心——从一开始就瞄准 AGI，想要改变世界、产生正向影响。

我觉得公司在这方面做得非常成功。ChatGPT 把一种"可用的智能"分发给了非常多的人，这本身就是一件非常了不起的事情。

**主持人**：你在推文里提到，你想做一些在 OpenAI 觉得无法进行的研究。能具体解释一下吗？

**Jerry**：是这样：在一家必须参与当下这种极其残酷、极其高压的竞赛、必须争夺"世界上最强 AI 模型"的公司里，有些事情就是很难做。这背后有几个方面的原因。

**其中一个因素是风险偏好**。公司愿意承担多大风险，会受到很多现实约束：比如不能落后于用户增长指标，比如 GPU 成本极其高昂。因此，向外界展示实力、持续拥有最强模型，对所有主要 AI 公司来说都非常重要。但这确实会影响你愿意承担风险的"胃口"。

**另一个很难的取舍是组织架构**。公司有 org chart，而 org chart 往往决定了你能做什么研究。每个团队都需要一个身份、一个研究范围、一组他们要解决的问题。跨组织的研究就会变得非常困难。

我也不确定这是不是一个已经被完全解决的问题：当研究规模变得很大时，究竟该如何把研究组织好？研究本身喜欢动态，甚至可以说喜欢混沌；但一大群人需要秩序、结构和组织架构。

所以，"把组织架构交付出去（shipping your org chart）"成了一种非常普遍的现象，研究也不例外。你最终会做那些组织结构最容易支持的项目。而与此同时，我确实想做一些研究，但公司的组织结构并不容易支持我去做这些事情。

---

## 2 行业同质化：五家公司用同一套"配方"

**Jerry**：让我感到非常"难过"的事，就是**现在几乎所有 AI 实验室都在试图做和 OpenAI 一模一样的事情**。

OpenAI 显然是一家非常成功的公司，它在很多关键问题上做对了选择，把整个世界带进了"规模化 Transformer"的范式之中，也证明了：通过扩展机器学习模型的规模，确实可以为世界带来大量非常有价值、非常有用的能力。

**但问题是：这个世界究竟需要多少家"做完全同一件事"的公司？我不知道。竞争当然是好事，所以肯定不止一家更好。但现在我们大概已经有五家相当严肃、体量巨大的 AI 公司，基本上在用完全同一套"配方"，试图在同一套技术之上，做出一点点差异化的产品。**

也许这确实是对的选择，但我还是希望能看到更多多样性——更多模型层面的差异。

如果你去看现在世界上最好的那些模型，实际上很少有人真的能注意到它们之间的区别。我觉得应该做更多"盲测"：让人们分别和不同模型对话，看他们是否真的能分辨出哪个是哪个。**我敢说，99.9% 的用户根本察觉不出来这些模型有什么不同；在他们的感受里，这些模型几乎一模一样。**

即便背后是不同团队，在做一些细微不同的事情，但所有实验室都觉得"我们在这个点上做得稍微好一点""对方在另一个技巧上可能更强"，最终的结果却是：大家全都挤在一个非常接近的位置上。

**那真正的探索在哪里？真正的创新空间在哪里？真正能让你和别人拉开距离的差异化又在哪里？**

**主持人**：你在 OpenAI 待了这么久，在公司内部算是传奇人物之一，而且你的履历也证明，你参与的项目往往能做成。那从外界看，如果连你这样的人都觉得——自己真正想做的研究在公司里推进起来足够困难，以至于最后选择离开——这是不是一个不太好的信号？

**Jerry**：我觉得有时候，人和组织都会成长到一个阶段：必须意识到，彼此的道路需要分开。

对一家单一公司来说，非常重要的一点是：公司内部的人，必须在某种程度上对目标、对前进路径保持一致。而在某个时刻，我对"未来研究路径"的判断，和 OpenAI 选择的方向，至少在一些足够重要的点上，**出现了分歧**——包括接下来一年研究该是什么样子。

在这种情况下，我认为分开，反而比强行在分歧中继续合作要好得多。否则，那些分歧可能会不断积累、发酵。

所以我反而认为：不同公司去做同样的事情，在某种意义上是合理的。因为专注对于一家公司来说非常重要，而 OpenAI 很可能正在做所有"正确的事"。

也许只是我自己有一些不太现实的梦想；也许我对"还能做些什么其他事情"过于乐观——这完全有可能。

**很多公司必须专注于自己的核心路径，才能活下来，才能进入下一个阶段。所以在一个理想的世界里，应该有很多不同的公司，在做很多不同的事情。而研究者——尤其是那些很难去做自己并不真正相信之事的研究者——应该能找到一个地方，在那里，他们能投入到自己最相信的研究方向中。最终，历史会证明哪一条路是对的。**

正因为如此，我才会对"大家都在做同一件事"感到有点难过。因为在当下，如果你想做一些偏离主流机器学习路线的事情，真的非常难找到一个合适的地方。这大概是我目前最感到遗憾的一点。

---

## 3 Google 的"回归"还是 OpenAI 的"失误"？

**主持人**：你怎么看 Google 最近这一轮的"回归"？你是觉得意外、惊讶，还是说其实早就料到了？

**Jerry**：**我个人其实不太愿意把这件事称为"Google 的回归"。它应该被视为 OpenAI 的失误。**

OpenAI 确实在很多关键点上做对了事情，但也不可否认，在某些阶段出现过判断或执行上的失误，导致整体推进速度比它本可以达到的状态要慢。

在一种理想的执行情境里，如果你是一家已经取得领先优势的公司，而且拥有 OpenAI 那样的技术、人才和资源条件，那么你理论上是可以持续保持领先的。但如果在这个过程中，你做出了一些错误决策，而你的竞争对手做出了更多正确决策——而 Google 在最近一段时间里，确实做对了不少事情——那对方追上来，其实并不奇怪。

你也必须承认：Google 在硬件、算力和人才储备上，本身就有非常巨大的优势。事实上，在 OpenAI 刚起步的那些年里，Google 在几乎所有机器学习方向上，都是明显的行业第一。

**OpenAI 能真正跑出来，靠的主要不是资源优势，而是研究方向上的强烈信念**：对某一条具体技术路线、某一个具体长期赌注的坚定投入。

但让整个行业、让外部世界真正意识到"这是一个正确的赌注"，花的时间比很多人想象的要长得多。哪怕 GPT-2 训练完成了，GPT-3 训练完成了，后来 GPT-3.5 也出来了——在那个阶段，其实并没有太多人真正重视这件事。

你去 NeurIPS 这样的会议和研究者聊天，大家会觉得 OpenAI 很酷，但很多其他实验室的态度是："嗯，我们迟早也能复现。"语言模型确实挺有意思，但在他们看来，也就止步于"有意思"。

**真正的转折点，是 OpenAI 开始通过 ChatGPT 赚到钱**。那一刻，其他公司才突然意识到："好，这不只是研究展示，而是一个已经被验证的商业方向，我们必须认真投入了。"

这里其实存在一个很关键、但常常被忽略的时间窗口：**从你开始构建一项技术，到它真正被商业化，中间往往隔着一段很长的时间**。

这段时间，足够让其他公司观察、犹豫、评估风险，然后再决定是否下场。而在这个阶段，Google 显然开始非常认真地对待大语言模型这条路线。再叠加 OpenAI 在执行层面的一些失误，最终导致今天的结果：在模型能力和训练成果上，双方已经变得非常接近。

**主持人**：那你说的这些"失误"，具体指的是什么？

**Jerry**：我不太想展开讨论具体的内部决策细节，哪些判断是对的，哪些是错的。

但我想强调的核心其实很简单：**如果一家领先公司执行得足够好，那么在大多数情况下，它是可以把领先优势持续下去的。**

**而在现实中，很明显有一些事情的推进速度，比它本可以达到的节奏要慢。**

**主持人**：你的意思是技术层面的失误吗？因为从外界看，也确实发生了不少公司层面的戏剧性的狗血剧情，这些在某些阶段显然拖慢了整体节奏。

**Jerry**：这些事情有时候确实是相互关联的。

从技术角度来说，我并不认为"有人离开"这件事本身就一定构成问题。在任何一家公司，人来人往其实都很正常，也应该是一种常态。

**但如果离开变成了某种更深层问题的症状——比如有人觉得："公司在一些关键事情上做错了决定，我不再相信这家公司了，所以选择离开"——那这往往意味着，背后确实存在一些需要被正视的问题。**

所以回到我最初的判断：**确实有一些事情，推进得比它本可以做到的速度要慢。**

这并不否认 OpenAI 的成功，但也不能忽视这些失误带来的影响。

---

## 4 Anthropic 的"清晰感"

**主持人**：我们刚才聊了 Google，也聊了 Meta。但我想换一个角度问：在你们内部讨论、或者评估其他实验室的时候，有没有哪一家，让你们真的觉得"被震撼到了"？哪一家是你个人印象最深的？

**Jerry**：我得说，这是一个相对比较新的变化。

**在过去一年里，我对 Anthropic 的印象提升得非常明显。**

我本人其实从来不是那种特别在意模型"性格"的人。虽然我也听说过 Claude 的"性格"很好，可能确实如此，但这并不是我关注的重点。

**真正让我感到震撼的是几件事：他们在代码模型、编码 Agent 上的成果；以及他们围绕"开发者"建立起来的整体产品和品牌——还有最关键的一点：他们拥有一大群真正满意、甚至很开心的开发者用户。这是一项非常、非常了不起的成就。**

更重要的是：他们起步比 OpenAI 更晚；算力条件更受限制；团队规模也更小。在这样的前提下，他们依然做到了高度聚焦，并且执行得非常好。

他们在获取高质量算力方面遇到过不少现实困难，但即便如此，仍然做出了非常出色的产品。

这些产品正在明显改变人们开发软件的方式；而据我了解，也已经在**实质性地提升企业生产力**。

所以我真心觉得：他们做得非常好，值得祝贺。

**主持人**：他们确实看起来正处在一个"高光时刻"。我身边几乎所有人都在聊 Claude Code。我最近还采访了一个人——他在用 Claude"养活一盆植物"。（笑）可能是第一种被 AI 模型持续"照料"的生命体。我真的不知道他们是怎么做出一个几乎"人人都喜欢"的工具的。从 ChatGPT 到 Claude Code，这种程度的"普遍好评"，其实非常少见。

而且之前还有一件事：当大家被"切断使用"时，开发者的反应极其强烈——某种程度上，那种崩溃感甚至超过了 OpenAI 出事时的反应。连 Elon 都公开承认了这一点，说："是的，我们用得太多了，这是个警醒，我们得把自己的东西做得更好。"

**Jerry**：在 OpenAI，我们其实也开发 Codex 有一段时间了——它算是我们自己的"Claude Code 版本"。

我个人觉得 Codex 也挺不错的。有点好笑的是：我自己其实并没有怎么用过 Claude Code。毕竟当时我还在 OpenAI 工作，也没太多机会去亲自用。

我也是想说得客气一点。所以我确实没法给出太多一手对比体验。但至少从推特上的反馈来看，**Claude 确实被全球开发者非常、非常喜欢**。

---

## 5 做点跟 OpenAI 不同的事情

![访谈配图](https://cdn.jsdelivr.net/gh/maxzyma/articleread/openai-veteran-jerry-tworek-interview/images/image_05.png)

**主持人**：结合我们前面的讨论，我对你的理解是：你一直是从一种很纯粹的智识和科学兴趣出发的人。你在 reasoning 上的很多工作，本质上都指向一个长期目标——你想创造"AI 科学家"。

所以当我看到你说要离开 OpenAI 时，我忍不住在想：你是不是已经不太想继续待在这场"基础模型竞赛"里了？听你说话的感觉，更像是想换一条路走。我甚至会想象，你会不会干脆跑去做生物科技之类的方向，用完全不同的方式继续追这件事。

**Jerry**：如果我能克隆自己、同时做很多件不同的事情，我真的会非常愿意。但长话短说：有一天我突然意识到——我对自己过去的人生很满意，也为自己做过的事情感到骄傲；但我现在真正想做的，是押一两个、甚至两三个非常非常大的研究赌注，然后看看能不能把它们做成。

我一直觉得，人应该更愿意冒风险。至少从我的观察来看，我可能算是那种风险承受能力比较高的人——愿意去追一些看起来很野、很不确定、甚至有点离谱的想法。所以我觉得，我应该把这种特质用在更有意义的事情上。

**主持人**：那你脑子里的这些想法，如果真要落地，大概需要多久？是一年左右的项目，还是说你说的"风险"，意味着你愿意花四五年时间去追一件事，而它最后甚至可能还不如现有方案？

**Jerry**：我肯定愿意投入很多时间。但与此同时，我也非常坚定地认为：**研究应该尽可能快地推进**。

做得慢，本身并不值得骄傲。从"把研究执行好"这个角度看，我希望它能更快。

不过，真正关键的，其实是我之前反复提到的两个词：**聚焦（focus）和信念（conviction）**。

如果你同时做很多事情，几乎注定每件事都只能做一小部分。你的注意力会被摊薄，资源也会被摊薄。研究实验室经常会说：算力不够，算力限制拖慢了研究。这当然是真的，而且是重要因素之一。但很多时候，更核心的问题其实是：不够聚焦。一天之内，一个人的注意力只能真正放在有限的几件事情上。

我很喜欢对和我共事过的研究者说一句话：**少跑一点实验，把每一个实验想得更深**。因为有时候，你花几个小时什么实验都不跑，只是盯着结果、反复分析数据——反而更容易带来真正的突破，而不是不停地"多跑"。

所以像 OpenAI 这样的公司，算力其实非常多。但如果算力被分散到太多项目上，效果反而会被稀释。如果把算力集中到更少、更聚焦的项目上，算力往往是够用的。

但这又回到了风险和信念的问题。如果你同时做三个项目，只要有一个成功，其实就已经算不错了；另外两个被砍掉，也完全可以接受。如果三个都成功，那当然更好。但如果你只做一个项目，它往往会推进得更快——因为你足够聚焦、也足够坚定。当然，代价是：如果它失败了，你会非常惨；但如果它成功了，你可能会拥有世界上最好的模型。

而对 OpenAI 这样规模的公司来说，现在确实很难做到一件事：**把整个公司押注在一个全新的、完全不同的方向上，同时不在乎下个季度 Gemini 会不会更强。**

这真的非常难。它需要一种非常特殊类型的人，才愿意这么做。

我觉得，这就是问题的核心。

---

## 6 研究方向：下一个突破口是什么？

**主持人**：就你现在这些正在吸引你的研究方向来说——你能不能稍微给我们一点提示？

**Jerry**：我现在最兴奋的研究方向大概有两个。主要原因也很简单：我不觉得重复去做各大实验室正在做的那套事情有什么意义。现有体系里当然还有很多可以微调、可以改进的地方，但我认为有两个方向长期被低估了投入——或者至少没有得到足够的资源与重视。

**第一，是某种意义上的"架构创新"**。我觉得我们对 Transformer 架构有点过于"路径依赖"了。Transformer 确实很伟大，也被非常深入地研究过。人们一直试图在本地做一些小改动，让 Transformer 更强，但这件事并不容易。虽然也有一些相当成功的改进——比如稀疏化非常成功；还有各种让注意力计算更便宜的方法，也取得了不错的效果。

但 Transformer 会是机器学习的最终架构吗？显然不会。尽管 Transformer 的发明者做出了惊人的贡献，并且几乎定义了接下来十年的机器学习格局，但我相信一定还有更多可能。

一定存在一些训练大模型的方法——它们也许有点像 Transformer，也许完全不像。我觉得这是一个值得去解决的问题。甚至如果没有别人去做，我也愿意卷起袖子自己上，试着把它做出来。

**第二，相对更"热门"，但我觉得几乎没有人把它做得真正好，那就是持续学习（continual learning）**：如何把测试时（test time）与训练时（train time）真正打通、真正融合起来。

人类显然就是这样运作的：我们没有一个"专门学习模式"和一个"专门回答问题模式"。学习与反应是连续发生的、时时

刻刻都在进行。我觉得我们的模型也应该更接近这种状态。

这可能是我们在把模型真正称为 AGI 之前，最后几个关键能力要素之一。如果模型不能从它看到的数据中持续学习，它就仍然显得有点受限——甚至有点"笨"。

**主持人**：关于"世界模型"的方向呢？Google 在做这个，Yann LeCun 似乎也在推动类似的想法。

**Jerry**：**这个方向毫无疑问是正确的**。真正有挑战性的，是：如何把从世界建模中学到的表征，与强化学习真正结合起来。

强化学习教会模型"技能"——让它学会如何在世界中实现自己的目标。但在此之前，模型必须先理解世界，否则它连"如何设定目标""如何达成目标"都无从谈起。

正因为如此，这两件事情必须结合起来。

**如果有人能在一个高质量世界模型之上，真正把强化学习跑通，那将会是一个非常令人振奋的时刻。**

---

## 7 AGI 时间线

**主持人**：说到 AGI，你自称对 AI 是"谨慎的乐观主义者"。那你觉得我们现在处在 AGI 时间线的哪个位置？

**Jerry**：我个人的看法是：我对时间线做了一点更新。

我一直认为，把强化学习规模化（scaling reinforcement learning）是通向 AGI 的必要部分。一年、或一年半之前，我非常坚定地认为：只要把 RL 规模化到我们的模型之上，那就是 AGI 了。但我确实不得不稍微修正这个判断。因为有些东西，只有当你真的到了"下一阶段"之后才看得见。

我们也必须承认：今天的模型在很多方面已经非常非常强了。就拿编码来说——"vibe coding"是我最喜欢的爱好之一，你现在可以非常快地写出很多东西。对一些十年前的人来说，如果你把今天这些能力展示给他们，他们可能已经会把它叫做 AGI 了。

所以我不觉得谈 AGI 还是一种多么离谱、多么疯狂的事。但至少按我的定义，现在的模型仍然不是 AGI——原因之一是：持续学习完全还没有以真正的方式被整合进模型体系里。

除此之外，还有很多问题。比如多模态感知：如果模型文本理解很强、编程也很强，但它看不见真实世界、不能看视频并且很好地理解视频，那我们能称它为 AGI 吗？

所以我认为，要真正达到那个"文明级里程碑"——构建 AGI——还有很多必要步骤要完成。

我觉得我的时间线仍在漂移。但与此同时，AI 领域移动得太快了：投资在年复一年累积增长，越来越多人进入 AI 领域，人才池变大，我们探索的想法数量也变多。

所以我不觉得"这个想法完全荒唐"。也许会早一点，也许会晚一点：可能是 2026，也可能 2027、2028、2029。我不觉得会比这更久太多。但确实还有很多工作要做。不过人们正在非常努力地做 AGI。

---

## 8 为什么大模型行业叙事变成了肥皂剧、真人秀

![章节图](https://cdn.jsdelivr.net/gh/maxzyma/articleread/openai-veteran-jerry-tworek-interview/images/image_06.png)

**主持人**：我一直在想，尤其"政变"那段时间：你做出来的东西被媒体炒得很热，还被卷进各种戏剧化叙事。我不知道"滑稽"这个词对不对，很多人其实还没弄清它到底是什么，就已经围观成现象了。你当时是什么感觉？

**Jerry**：**技术、概念、人类情绪、人类生活、人和人之间的协议与分歧——在现实里很难被切开来看。**

我们确实活在一个世界里：AI 领域的重要参与者之间，有一个非常复杂的关系网络，很多层次叠在一起。要把它完全理清楚，可能得历史学家花很多年、甚至几十年，才能真正弄明白到底发生了什么、哪些因素起了关键作用。

老实说，到现在为止，我对那段时间发生的一切也只剩下非常零散的记忆。我们也在不断"补课"——每当有新的证词出现、每当新的文件被披露，就会冒出一些新事实。未来某个时刻，肯定会有人把所有内容都挖出来、完整还原。

但现实世界就是这么复杂。我也确实觉得，也许应该有一种更健康的方式来讨论技术：找到一个更合适的讨论场域，让分歧能够被更充分、更有建设性地展开。但我们生活在这样一个世界里：没有完美解，也不存在一种绝对正确的讨论机制。

**主持人**：如果你先把技术放一边——我甚至报道过"挖人狂潮"。我越来越觉得，这个行业的叙事变得像肥皂剧、像真人秀，很多时候讨论的不是硬核科学，而是剧情、阵营和情绪。你会不会也觉得我们有点"跑偏"了？

**Jerry**：但到底是谁在制造这场肥皂剧？这才是问题。

**主持人**：嗯，说真的，这一轮比我经历过的任何技术周期都更"肥皂剧"。可能是赌注太高、钱太多，再加上挖人和各种戏剧化叙事，整个旧金山像活在一套自己的现实里。

我有时都替你们累——七八年一直在这种高压竞速里，你现在想停下来喘口气，我完全能理解。

**Jerry**：的确很消耗。

**但我可以跟你分享一句对我很有帮助的话：有一次，一个比我更有经验、更擅长应对压力的人跟我说——Jerry，这就像做俯卧撑。每经历一次艰难、紧张的时刻，你就更擅长应对压力一点。**

老实说，这七年让我练出了很强的心理和情绪韧性。我真的学会了在大量噪音、很多胡扯面前，把自己抽离出来，尽量保持稳定、保持定力。

不管外部发生什么——公司看起来要塌了也好，研究者流动也好，项目被重新分配也好——总会有事情在推进，总会有新的变化。

我听过有人把"挖人"这件事类比成体育队伍的转会。体育之所以还能运转，是因为有角色、有规则。我差点想说：可惜在加州的法律框架下，这类规则基本不可能出现。但我确实觉得，如果能有一些规则，可能会更健康。

因为确实存在这样一种现象：**有些人换工作的频率，比他们真正产出成果的频率还高**。

---

## 9 AI 研究是"明星驱动"的吗？

**主持人**：我们之前聊到 OpenAI 的人员流动时，你说公司是能扛住这些变化的。但从外部看，这个领域又很像是"明星驱动"的：比如 Alec Radford 那样的突破级贡献——你知道我指的是什么。

从行业行为上看，很多实验室似乎也在按"明星逻辑"行事。当然，这背后有大量集体协作，但确实也有一些时刻，看起来重大突破被"绑定"在少数几个人身上。但你刚才的反应，似乎并不完全认同这是一个"明星驱动"的行业。

**Jerry**：我觉得这是个很复杂的话题，但有两个看法可以同时成立。

一方面，确实存在这样的情况：在某些阶段，尤其是在 OpenAI，**一小撮人能产生远超常人的影响力**，推动真正突破性的成果，然后这些成果扩散到整个行业。我亲眼看到这种事情反复发生。

但另一方面，当我看到人们在不同公司之间频繁流动时，我很少看到这种流动本身，对公司产生"决定性影响"。

**我更相信的是：公司的结构、文化和运作方式，才是真正的研究引擎，而不完全取决于某一个研究者是否在这里。**

而且我也观察到一个现象：**那些频繁跳槽的研究者，反而往往没那么高产**——即便他们过去做过很好的工作。他们需要重新磨合，会被各种事情分散注意力，短期内也未必有新的突破性想法。

经验当然重要，但更重要的是：营造一种环境——强调个人责任、鼓励探索、并且真正为"做出伟大事情"提供条件。

在一个好的结构、好的文化、好的协作方式下，你完全可以建立很多团队，持续做出伟大的成果。

这件事并不依赖某一个"唯一的人"。归根结底，我认为：**研究结构、研究文化和协作方式，远比"某个特定的人是否在团队里"更重要。**

---

## 10 OpenAI 的压力甚至超过创业？

**主持人**：还有一个问题，除了"大家都在追同一套东西"之外，你觉得这个领域里还有没有什么"巨大的错误"？

**Jerry**：我不觉得存在那种特别"巨大的错误"。这个行业里的人，其实都很难犯那种一眼就能看出来的致命错误。

**真正的问题更像是：你愿意花多少精力去探索"其他可能性"？又有多少精力，继续沿着你已经走得很顺的那条路往前推。**

**主持人**：那我换个问法，可能更准确一点。有没有一些你觉得被明显低估、被忽视的研究方向？它们本该得到更多关注，但现在没有。

**Jerry**：老实说，这样的想法非常多。但这些想法最缺的，往往不是"它们不存在"，而是：**缺关注、缺算力、缺资源**。

这里还有一个比较有意思的现象。很多研究者——包括学术界——很擅长、也很喜欢做"从 0 到 1"的事情：提出一个新想法，证明它"有点能跑"，然后就发表出来。而我觉得，我自己、以及我在 OpenAI 共事过的团队，**真正特别擅长的一件事，是"从 1 到 100"**：拿一些已经有初步证据的新想法——它们很不同，也不成熟——然后想办法把它们在大规模上做得可靠、稳定、可落地。

要训练前沿模型，把一种技术真正嵌进系统里，会涉及大量非常具体、非常琐碎、但又极其关键的工程和研究工作。如果执行不好，可能要花上好几年；但如果你有一套好的方法和节奏，可能几个月就能完成。这也是我未来很想继续多做的一类事情。

**主持人**：我听一位正在经营自己公司的人说过一句让我很震撼的话：**在 OpenAI 工作，比自己创业还更有压力**。从很多方面看，OpenAI 的确是一个压力极大的地方。

**Jerry**：是的。我确实不知道接下来要做什么。

---

## 总结：对话金句

> "如果你想做一些偏离主流机器学习路线的事情，真的非常难找到一个合适的地方。"

> "这世上大概已经有五家相当严肃、体量巨大的 AI 公司，基本上在用完全同一套'配方'，试图在同一套技术之上，做出一点点差异化的产品。"

> "我个人其实不太愿意把这件事称为'Google 的回归'。它应该被视为 OpenAI 的失误。"

> "当我看到一个新技术真正开始工作时——如果你在那一刻不感到一点害怕、不感到一点担忧，那我会觉得你没有在负责任地对待自己的工作。"

> "当一个行业被持续围观，你不是在安静地做研究，而是在聚光灯下跑一场没有终点的马拉松。"

> "把整个公司押注在一个全新的、完全不同的方向上，同时不在乎下个季度 Gemini 会不会更强——这真的非常难。"

> "在 OpenAI，每一年都像是在一家完全不同的公司里。"

> "研究结构、研究文化和协作方式，远比'某个特定的人是否在团队里'更重要。"

> "少跑一点实验，把每一个实验想得更深。"

---

*图片来源：InfoQ 公众号原文*
*播客来源：Core Memory，YouTube 链接：https://www.youtube.com/watch?v=VaCq4u5c78U*

![二维码](https://cdn.jsdelivr.net/gh/maxzyma/articleread/openai-veteran-jerry-tworek-interview/images/image_07.png)
