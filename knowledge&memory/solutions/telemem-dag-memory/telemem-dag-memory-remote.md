# 让Agent画思维导图稳固长期记忆：新框架实现稳定长期学习，准确率提升38%

> 来源：微信公众号 量子位，2026-01-26
> 原文链接：https://mp.weixin.qq.com/s/_OPVPZ1PU3XpLfOfQuoQ

思维导图曾被证明可以帮助学习障碍者快速提升成绩，那么当前已经可堪一用的智能体系统如果引入类似工具是否可以帮助改善长期学习记忆能力呢？有研究团队做出了探索性尝试。

在长上下文和Agent应用不断落地的过程中，越来越多研究者开始意识到，如果Agent需要像人一样持续学习、不断积累经验并形成稳定的认知结构，仅依赖传统RAG的"检索式记忆"已经难以支撑长期演化。

传统RAG在"长期记忆管理"和"持续学习承载能力"两个层面，正在同时暴露出结构性瓶颈。

向量数据库擅长相似度检索，却难以表达时间顺序、因果关系和状态演化；随着历史数据规模持续增长，系统成本不断上升，也更容易出现记忆漂移、逻辑断裂以及隐性的知识遗忘。

当Agent的交互跨度从"单轮问答"扩展到"跨月甚至跨年的持续运行"时，这种碎片化记忆结构会直接限制其学习能力与行为稳定性。

近期，**中国电信人工智能研究院（TeleAI）**研究团队提出了一种基于**DAG（有向无环图）**的通用记忆框架——**TeleMem**，从"数据结构层"重新设计Agent的记忆组织方式，使记忆不仅可检索，而且可持续累积、可回溯、可演化。

该架构通过统一表征与索引、离线与在线协同更新，以及基于闭包的上下文检索机制，构建了一套结构稳定、面向规模化、能够支撑长期持续学习的记忆系统。

![TeleMem架构图](https://cdn.jsdelivr.net/gh/maxzyma/articleread/telemem-dag-memory/images/image_01.jpg)

此项成果由中国电信集团CTO、首席科学家、中国电信人工智能研究院（TeleAI）院长李学龙教授指导，已在GitHub开源。

---

## 为什么传统RAG难以支撑长期记忆与持续学习？

当前主流RAG架构通常以向量数据库为核心：

- 每一段记忆被编码为独立向量
- 检索阶段依赖Top-K相似度匹配
- 上下文拼接交由大模型自行理解

这种范式在短文本问答场景表现良好，但在长期交互和Agent场景中逐渐暴露出明显问题：

### 1. 缺乏时间与因果结构

向量只能表达语义相似度，无法描述事件先后关系、状态依赖和决策演化路径。

这使系统难以形成稳定的学习轨迹，无法区分"新知识是补充、修正还是替代旧认知"。

### 2. 上下文碎片化严重

检索返回的是离散片段，模型需要自行补全逻辑链条，容易产生幻觉与不一致推理。

在持续学习场景下，这种碎片化上下文会导致认知漂移和策略不稳定。

### 3. 索引随规模恶化

随着历史数据增长，写入成本、索引漂移和存储冗余不断累积，系统很难在长期运行中保持稳定学习能力。

本质上，RAG面临的并不是检索精度问题，而是其记忆数据结构难以承载跨时间的知识积累、状态演化与因果依赖，因此难以支持真正意义上的持续学习。

---

## TeleMem：把"记忆"从向量集合升级为可演化的时序因果图

TeleMem的核心设计，是将所有历史记忆统一组织为一张"**有向无环图（DAG）**"，把"记忆存储"升级为"可演化的认知结构"，使Agent的每一次交互结果都成为可被持续累积、回溯和修正的学习状态，而不再只是一次孤立的向量写入。

在这张图里：

### 节点（Node）

表示一段已经被语义理解并稳定固化的记忆状态，包含内容语义、向量表征和时间信息。每个节点对应一次对话状态、一次关键事件，或一次阶段性的认知更新结果。

### 依赖边（Edge）

表示节点之间显式的语义与因果依赖关系，即"当前认知由哪些历史状态条件转化而来"。边为有向结构，并严格满足时间约束（只能从更早节点指向更新节点），从而保证语义单调演化，避免循环依赖与认知回滚。整体图保持为最小因果骨架：仅保留不可约依赖，若两节点之间已存在间接可达路径，则对应的直连边会被剪除，以消除传递冗余并维持依赖结构的最简性。

### 路径（Thread）

多条依赖边串联起来，形成可追溯的记忆演化链，不仅用于描述话题、状态或角色在时间维度上的连续演进，也天然刻画了Agent的认知更新与持续学习轨迹。

为了保证整张图的连通性，系统还引入虚拟起点节点，用于挂载没有显式前置依赖的学习起点，避免孤立认知片段的产生。

换句话说，系统存储的不再是彼此孤立的向量片段，而是一张具备时间顺序、因果约束和可回溯结构的"认知记忆网络"，能够支持长期稳定的知识积累与演化。

### 统一的语义节点：将经验压缩为可复用的学习状态

在TeleMem中，节点不再只是一个embedding，而是承载多类型语义表征的复合结构，覆盖用户状态、交互事件和环境对象等多个语义层面：

- **用户与角色记忆**：刻画用户画像、长期偏好以及角色状态随时间的演化
- **事件与情境记忆**：对对话片段、视觉内容等交互过程进行语义摘要，形成稳定的事件级学习表示
- **对象与环境状态记忆**：记录物理对象或环境属性的结构化状态变化

这些节点保存的是"被模型理解并稳定固化后的语义状态"，可以视为持续学习过程中的阶段性认知结果，而非原始文本、像素或传感数据。这种抽象显著降低了存储与索引成本，同时减少噪声积累，使长期知识能够稳定复用并支持跨任务迁移。

### 因果连边与DAG约束：为持续学习提供结构稳定性

节点之间通过显式依赖边连接，每条边同时表达三类约束：

- **时间顺序约束**：每个节点只能依赖时间上早于自身的父节点，从结构上避免循环学习与状态回滚
- **语义依赖约束**：明确刻画当前认知形成所依赖的上下文信息
- **逻辑约束**：依赖图维持为最小因果骨架，仅保留不可约依赖关系；若两节点之间已存在可达路径，则对应直连边会被剪除，以避免冗余、冲突或被其他路径覆盖的依赖

DAG结构天然避免循环依赖，使历史认知可以稳定回溯和并行遍历，从结构层面降低灾难性遗忘与隐性知识覆盖的风险，也为后续的增量构图、长期维护和闭包检索提供可靠基础。

在这种结构下，Agent的学习不再是无序追加，而是沿着可解释、可约束的认知轨迹持续演化。

---

## 表征与索引的双层协同更新机制

TeleMem将记忆系统拆分为两个协同演化的层次：

- **表征层（Representation Layer）**：负责语义内容的抽象、压缩与状态演化，如用户画像、事件摘要和多模态语义表示
- **索引层（Index / Graph Layer）**：负责维护节点之间的时间约束、因果依赖与可检索拓扑结构

核心挑战在于：表征持续变化，而索引必须同步反映这些变化，同时保持可扩展性与一致性。为此，TeleMem设计了**Offline Batch**与**Online Stream**两条更新路径，覆盖不同时间尺度下的更新需求。

### Offline Batch：全量表征整合与离线并行构图

![离线并行构图](https://cdn.jsdelivr.net/gh/maxzyma/articleread/telemem-dag-memory/images/image_02.png)

#### （1）表征层更新：离线并行聚类决策

在TeleMem中，表征层并不是简单累积对话内容，而是通过一套**高度并行的批处理流水线**，将原始交互持续压缩为稳定、可管理的长期语义记忆。

整个写入流程支持多层级并行：

- 不同对话轮次之间可并行处理
- 同一轮中多个语义摘要可并行抽取与检索
- 聚类后的多个语义簇可并行决策更新

这使得表征更新在规模扩展时仍能保持稳定吞吐。

主要包括三个步骤：

1. **记忆抽取**：并行抽取标准化记忆表征，如用户与Agent的角色摘要、事件级语义单元，用于刻画稳定状态与关键交互信息
2. **检索对齐**：并行匹配新生成表征与已有记忆，主动发现语义重复与高度相关内容，避免无序膨胀
3. **聚类决策**：对候选内容进行全局聚类，并对不同语义簇并行执行合并、更新或淘汰操作，持续压缩冗余信息

该流程在保证语义质量的同时，实现了可并行扩展的写入效率，使表征更新可以随数据规模线性扩展。

#### （2）索引层更新：离线并行构图

在Offline Batch阶段，系统采用并行化的批量构图方式，直接从全量节点构建完整索引结构。

其效率优势主要来自三个工程设计：

- **索引只读**：构图期间索引保持只读，多线程可并行检索
- **时间约束天然无环**：节点仅依赖历史节点，任务之间几乎无冲突
- **批量追加写入**：边统一批量收集并合并，避免随机写与锁竞争

这种方式将传统串行构图转化为大规模并行任务，在数据规模扩展时仍能保持稳定吞吐。

离线并行构图将"构建大规模记忆索引"转变为可线性扩展的并行计算问题。

### Online Stream：增量表征演化与局部索引维护

在线阶段面向实时交互，强调低延迟与持续可用性：

- 表征层持续吸收新事件，对用户画像、对象状态和多模态摘要进行增量更新
- 索引层基于检索完成近似挂载，并在必要时对局部结构进行调整
- 跨层联动确保表征变化能够及时反映到索引结构中

在线路径允许短期近似误差，但保证结构持续稳定演化。

### 双路径的收敛关系

系统不要求在线阶段始终保持全局最优：

- 在线维持近似正确与局部一致
- 离线周期性执行全量收敛与结构整理

两者形成稳定闭环，在吞吐、稳定性和长期可维护性之间取得平衡。

---

## 读取阶段：从Top-K拼片段到因果闭包还原

传统RAG的读取方式，本质是"Top-K相似片段拼接"：从向量库检索若干最相似文本块，再直接拼接给模型。这在短问答场景通常有效，但在长对话和长期记忆场景中容易失效，主要体现在三点：

- 只看相似度，不保证前置条件齐全
- 缺乏结构约束，容易混淆不同时间线或线程
- 上下文碎片化，更像抽样而非复原

TeleMem的读取目标更接近"复原一段完整因果上下文"。系统会构造一个**最小闭包子图（Minimal Closure Subgraph）**，将回答所需的前置依赖一并补齐：

1. **种子定位**：通过Top-K找到最相关节点
2. **因果回溯**：沿依赖边反向遍历，补齐必要祖先
3. **闭包构造**：形成自洽的上下文子图
4. **线性化输出**：按时间顺序组织为模型输入序列

最终获得的不再是零散片段，而是一段前因后果相对完整的上下文，从而显著降低碎片化带来的推理偏差。

![因果闭包还原](https://cdn.jsdelivr.net/gh/maxzyma/articleread/telemem-dag-memory/images/image_03.gif)

在复杂多模态查询场景中，记忆读取可采用ReAct风格的推理范式，通过多轮think–act–observe迭代，在文本记忆与视频内容之间逐步补全信息并收敛到可靠结论。

---

## 实验结果与性能表现

在中文长程对话基准**ZH-4O（平均约600轮、多角色场景）**测试中，TeleMem的准确率达到**86.33%**，相比RAG基线提升约**38个百分点**，相比Mem0提升约**19个百分点**。

![实验结果对比](https://cdn.jsdelivr.net/gh/maxzyma/articleread/telemem-dag-memory/images/image_04.jpg)

在保持较高准确率的同时，TeleMem显著降低了推理成本与延迟，不再需要每次将完整历史上下文输入模型，记忆规模也不再受限于模型的Context Window，可稳定支持千轮乃至万轮对话。

同时，该系统支持多模态记忆管理，在复杂、多源信息场景下仍能保持较好的组织与检索稳定性。

---

## 趋势观察：Agent记忆正在走向结构化与可演化

TeleMem的意义不仅是一种工程优化，也反映出一个更长期的技术趋势：

**Agent能力正在从"检索系统设计"逐步转向"记忆结构与持续学习机制设计"。**

当Agent从一次性任务执行者演进为长期运行、持续适应环境的智能体时，记忆不再只是信息缓存层，而成为承载学习、认知演化与策略稳定性的核心基础设施。

系统是否能够稳定积累经验、避免隐性遗忘、并在时间维度上形成可解释的认知结构，将直接决定Agent的长期智能上限。

未来的智能体需要具备：

- **可追溯的状态与认知演化路径**：能够明确知道当前决策基于哪些历史经验与学习结果
- **可持续维护的长期记忆与增量学习能力**：支持知识稳定累积、低成本扩展和持续更新，而非简单覆盖与堆叠
- **可解释的上下文回溯与学习来源追踪能力**：使行为与知识更新具备可审计性和可调控性

从这个角度看，结构化记忆系统不仅是在提升检索效率，而是在为Agent构建一个**可持续学习、可演化认知与长期稳定行为的底层支撑层**。

![长期智能体演进](https://cdn.jsdelivr.net/gh/maxzyma/articleread/telemem-dag-memory/images/image_05.png)

它可能成为下一代Agent基础设施从"工具型系统"迈向"长期智能体"的关键分水岭。

---

## 链接

**GitHub：**
- https://github.com/TeleAI-UAGI/Awesome-Agent-Memory
- https://github.com/TeleAI-UAGI/telemem

**论文链接：**
- https://arxiv.org/pdf/2512.21567
- https://arxiv.org/pdf/2601.06037
